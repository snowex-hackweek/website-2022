{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5276c910-43d9-4b68-961a-f385b9b748ad",
   "metadata": {},
   "source": [
    "# SnowEx Database Preview\n",
    "(15 minutes)\n",
    "\n",
    "<img src='https://i.gifer.com/FH7W.gif' alt='fireworks' style='width:250px' />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f2e05b2-ba43-4365-9194-679ea246acb6",
   "metadata": {},
   "source": [
    "Learning Objectives:\n",
    "\n",
    "* First taste of the database!\n",
    "* Code snippets to extract and prep data.\n",
    "* Generate ideas for project pitches."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3a30b8-2b65-4511-b6ab-f27263376d29",
   "metadata": {},
   "source": [
    "## The Basics\n",
    "### How are the data contained?\n",
    "<img src='./content/03_database-tables.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc326f2c-5bc2-4b7d-ab82-2c6345a7f3a0",
   "metadata": {},
   "source": [
    "## Set Up Computing Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0348404d-e9af-43a6-b03e-bdf245c4a58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard imports\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt \n",
    "import datetime\n",
    "\n",
    "# some mapping widgets\n",
    "import ipyleaflet\n",
    "from ipyleaflet import Map, GeoData, Rectangle, basemaps, LayersControl, basemap_to_tiles, TileLayer, SplitMapControl, Polygon, MagnifyingGlass\n",
    "import ipywidgets\n",
    "\n",
    "# database imports\n",
    "from snowexsql.db import get_db\n",
    "from snowexsql.data import PointData, LayerData, ImageData, SiteData\n",
    "from snowexsql.conversions import query_to_geopandas, query_to_pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30dd84cd-7a0a-45d3-81e6-33933fd286cd",
   "metadata": {},
   "source": [
    "**POINTER -->** Notice where I import the **four** primary database tables. Can anyone call out what code line does this from the code block above?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4f0d3f-d54e-428f-953b-6e99b8a9b130",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the database\n",
    "db_name = 'snow:hackweek@db.snowexdata.org/snowex'\n",
    "engine, session = get_db(db_name)\n",
    "\n",
    "print('SnowEx Database successfully loaded!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1149b3a2-a87e-4c4b-b8ba-d5598fc01bcb",
   "metadata": {},
   "source": [
    "### What's the first thing you might like to do using the database?\n",
    "Find overlapping data for data analysis comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "661627b7-b045-467b-9a07-c6123b78084e",
   "metadata": {},
   "source": [
    "### Example 1: Let's find all the pits that overlap with an airborne sensor of interest!\n",
    "First, it would be helpful to know, which of the airborne sensors are part of the database, right?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac47cd21-f379-43fa-ad11-64be6109cba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query the session using .observers() to generate a list\n",
    "qry = session.query(ImageData.observers)\n",
    "\n",
    "# Locate all that are distinct\n",
    "airborne_sensors_list = session.query(ImageData.observers).distinct().all()\n",
    "\n",
    "print('list of airborne sensors by \"observer\" name: \\n', airborne_sensors_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d02ca8-a2d6-4afb-a09b-ccfe73b3220c",
   "metadata": {},
   "source": [
    "### 1a). Unsure of the flight date, but know which sensor you'd like to overlap with, here's how: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2eaf87-8c62-4a20-93c3-13ada37c3486",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Airborne sensor from list above\n",
    "sensor = 'UAVSAR team, JPL'\n",
    "\n",
    "# Form a query on the Images table that returns Raster collection dates\n",
    "qry = session.query(ImageData.date)\n",
    "\n",
    "# Filter for UAVSAR data\n",
    "qry = qry.filter(ImageData.observers == sensor)\n",
    "\n",
    "# Grab the unique dates\n",
    "qry = qry.distinct()\n",
    "\n",
    "# Execute the query \n",
    "dates = qry.all() \n",
    "\n",
    "# Clean up the dates \n",
    "dates = [d[0] for d in dates] \n",
    "dlist = [str(d) for d in dates]\n",
    "dlist = \", \".join(dlist)\n",
    "print('%s flight dates are: %s' %(sensor, dlist))\n",
    "\n",
    "# Find all the snow pits done on these days\n",
    "qry = session.query(SiteData.geom, SiteData.site_id, SiteData.date)\n",
    "qry = qry.filter(SiteData.date.in_(dates))\n",
    "\n",
    "# Return a geopandas df\n",
    "df = query_to_geopandas(qry, engine)\n",
    "\n",
    "# View the returned dataframe!\n",
    "print(df.head())\n",
    "print(f'{len(df.index)} records returned!')\n",
    "\n",
    "# Close your session to avoid hanging transactions\n",
    "session.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf18e03c-2ee7-4798-b805-83761b20f66b",
   "metadata": {},
   "source": [
    "### 1b).Want to select an exact flight date match? Here's how:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119b861a-fed4-48c0-b463-193d52787afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick a day from the list of dates\n",
    "dt = dates[0] \n",
    "\n",
    "# Find all the snow pits done on these days \n",
    "qry = session.query(SiteData.geom, SiteData.site_id, SiteData.date)\n",
    "qry = qry.filter(SiteData.date == dt)\n",
    "\n",
    "# Return a geopandas df\n",
    "df_exact = query_to_geopandas(qry, engine)\n",
    "\n",
    "print('%s pits overlap with %s on %s' %(len(df_exact), sensor, dt))\n",
    "\n",
    "# View snows pits that align with first UAVSAR date\n",
    "df_exact.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8357fbd6-efd5-4ea2-bea5-ff62337a3b52",
   "metadata": {},
   "source": [
    "### 1c). Want to select a range of dates near the flight date? Here's how:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db746402-510e-4a0d-a10f-cad953803eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Form a date range to query on either side of our chosen day \n",
    "date_range = [dt + i * datetime.timedelta(days=1) for i in [-1, 0, 1]]\n",
    "\n",
    "# Find all the snow pits done on these days \n",
    "qry = session.query(SiteData.geom, SiteData.site_id, SiteData.date)\n",
    "qry = qry.filter(SiteData.date.in_(date_range))\n",
    "\n",
    "# Return a geopandas df\n",
    "df_range = query_to_geopandas(qry, engine)\n",
    "\n",
    "# Clean up dates (for print statement only)\n",
    "dlist = [str(d) for d in date_range]\n",
    "dlist = \", \".join(dlist)\n",
    "\n",
    "print('%s pits overlap with %s on %s' %(len(df_range), sensor, dlist))\n",
    "\n",
    "# View snow pits that are +/- 1 day of the first UAVSAR flight date\n",
    "df_range.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73bc94cb-7789-4a21-bb08-fedc10c8cabf",
   "metadata": {},
   "source": [
    "### 1d). Have a known date that you wish to select data for, here's how:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2163595b-12a2-4ae9-a36c-ce544d9857ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all the data that was collected on 2-12-2020\n",
    "dt = datetime.date(2020, 2, 12)\n",
    "\n",
    "#--------------- Point Data -----------------------------------\n",
    "# Grab all Point data instruments from our date\n",
    "point_instruments = session.query(PointData.instrument).filter(PointData.date == dt).distinct().all()\n",
    "point_type = session.query(PointData.type).filter(PointData.date == dt).distinct().all()\n",
    "\n",
    "# Clean up point data (i.e. remove tuple)\n",
    "point_instruments = [p[0] for p in point_instruments if p[0] is not None]\n",
    "point_instruments = \", \".join(point_instruments)\n",
    "point_type = [p[0] for p in point_type]\n",
    "point_type = \", \".join(point_type)\n",
    "print('Point data on %s are: %s, with the following list of parameters: %s' %(str(dt), point_instruments, point_type))\n",
    "\n",
    "#--------------- Layer Data -----------------------------------\n",
    "# Grab all Layer data instruments from our date\n",
    "layer_instruments = session.query(LayerData.instrument).filter(LayerData.date == dt).distinct().all()\n",
    "layer_type = session.query(LayerData.type).filter(LayerData.date == dt).distinct().all()\n",
    "\n",
    "# Clean up layer data \n",
    "layer_instruments = [l[0] for l in layer_instruments if l[0] is not None]\n",
    "layer_instruments = \", \".join(layer_instruments)\n",
    "layer_type = [l[0] for l in layer_type]\n",
    "layer_type = \", \".join(layer_type)\n",
    "print('\\nLayer Data on %s are: %s, with the following list of parameters: %s' %(str(dt), layer_instruments, layer_type))\n",
    "\n",
    "#--------------- Image Data -----------------------------------\n",
    "# Grab all Image data instruments from our date\n",
    "image_instruments = session.query(ImageData.instrument).filter(ImageData.date == dt).distinct().all()\n",
    "image_type = session.query(ImageData.type).filter(ImageData.date == dt).distinct().all()\n",
    "\n",
    "# Clean up image data \n",
    "image_instruments = [i[0] for i in image_instruments]\n",
    "image_instruments = \", \".join(image_instruments)\n",
    "image_type = [i[0] for i in image_type if i[0] is not None]\n",
    "image_type = \", \".join(image_type)\n",
    "print('\\nImage Data on %s are: %s, with the following list of parameters: %s' %(str(dt), image_instruments, image_type))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d4b0a9-d88e-42ad-b591-192557dd6777",
   "metadata": {},
   "source": [
    "### Example 2: Let's plot some snow pit temperature profiles from open canopy sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd65808-0f5f-4cee-93b6-af91ce8bddd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# database imports (again)\n",
    "from snowexsql.db import get_db\n",
    "from snowexsql.data import PointData, LayerData, ImageData, SiteData\n",
    "from snowexsql.conversions import query_to_geopandas, query_to_pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ac7827-04c7-48ad-b04e-ac8c4f3c4380",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the database\n",
    "db_name = 'snow:hackweek@db.snowexdata.org/snowex'\n",
    "engine, session = get_db(db_name)\n",
    "\n",
    "print('SnowEx Database successfully loaded!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e382cd-1a2e-48c1-83b1-77e99b4c6b8d",
   "metadata": {},
   "source": [
    "### Query the SiteData for a list of Time Series sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010b2995-3ee3-4315-8e50-2a8c882490fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# query all the sites by site id\n",
    "qry = session.query(SiteData.site_id).distinct()\n",
    "\n",
    "# filter out the Grand Mesa IOP sites (this also removes Grand Mesa Time Series sites, but okay for this example)\n",
    "qry = qry.filter(SiteData.site_name != 'Grand Mesa') # != is \"not equal to\"\n",
    "\n",
    "# second filter on open canopy sites\n",
    "qry = qry.filter(SiteData.tree_canopy == 'No Trees')\n",
    "\n",
    "# execute the query\n",
    "ts_sites = qry.all()\n",
    "\n",
    "# clean up to print a list of sites\n",
    "ts_sites = [s[0] for s in ts_sites]\n",
    "ts_sites_str = \", \".join(ts_sites)\n",
    "print('list of Time Series sites:\\n', ts_sites_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56dc16b4-a2c9-4a31-a2ee-43aa21dece58",
   "metadata": {},
   "source": [
    "### Hold up, how did you know the 'special strings' to use?\n",
    "If you want to quickly view the list of options available for a specific table column, try this:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cdb4c35-fe72-49b2-a062-e784c1f5b0f5",
   "metadata": {},
   "source": [
    "1. Begin by going to the [Database Structure](https://snowexsql.readthedocs.io/en/latest/database_structure.html) page\n",
    "2. Scroll down to Sites Table (for this example)\n",
    "3. See the list of column options in the table? \n",
    "\n",
    "<img src='./content/03_db-structure-column-lookup.png'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736c74c9-5237-4ee5-9d5e-f561361772ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the SiteData table, and from the link above use the columns you have access to:\n",
    "locations = session.query(SiteData.site_name).distinct().all()\n",
    "print('Regional Locations are: \\n', locations)\n",
    "\n",
    "canopy_options = session.query(SiteData.tree_canopy).distinct().all()\n",
    "print('\\nCanopy Options are: \\n', canopy_options)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b38596e4-d8f9-41ab-a606-0ec1a0c19a31",
   "metadata": {},
   "source": [
    "### Okay, read for the big piece? Let's plot temperature profiles through time at all the open sites\n",
    "Steps: \n",
    "1. Use the list of Time Series sites we queried above (the \"No Tree\" sites, remember!)\n",
    "2. Set up the figure and subplots and colorbar\n",
    "3. Loop over a sites (e.g. Bogus Upper) and data parameter (e.g. temperature) in one query command\n",
    "4. Loop over the dates and add a temperature profile plot to the figure. (This is a nested loop)\n",
    "5. Style the plot axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747df104-9192-4f48-8ba7-91539e4075ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. use the list of Time Series sites from above \n",
    "sites = ts_sites\n",
    "\n",
    "# 2. setup the subplot for each site \n",
    "fig, axes = plt.subplots(len(sites)%5+1, 5, figsize=(12, 25))\n",
    "\n",
    "# setup the colorbar\n",
    "cmap = matplotlib.cm.get_cmap('viridis')\n",
    "\n",
    "# 3. loop over sites and select the data parameter ('temperature')\n",
    "for i, site in enumerate(sites):\n",
    "    \n",
    "    # query the database by site and for temperature profile data \n",
    "    qry = session.query(LayerData).filter(LayerData.site_id.in_([site])).filter(LayerData.type == 'temperature') \n",
    "    \n",
    "    # convert to pandas dataframe  \n",
    "    df = query_to_pandas(qry, engine)  \n",
    "    \n",
    "    # create list of the unique dates (LayerData will have a lot of repeated dates, we only need a list per visit, not per measurement)\n",
    "    dates = sorted(df['date'].unique())\n",
    "    \n",
    "    # grab the plot for this site\n",
    "    ax = axes.flatten()[i]\n",
    "    \n",
    "    # counter to help with plotting\n",
    "    k=0\n",
    "    \n",
    "    \n",
    "    # 4. loop over dates & plot temperature profile\n",
    "    for j, date in enumerate(dates):\n",
    "        \n",
    "        # grab the temperature profile \n",
    "        profile = df[df.date == date]\n",
    "        \n",
    "        # don't plot it unless there is data, make sure the dataframe index is > 1\n",
    "        if len(profile.index) > 0:            \n",
    "            \n",
    "            # sort by depth so samples that are taken out of order won't mess up the plot\n",
    "            profile = profile.sort_values(by='depth')\n",
    "\n",
    "            # cast as a float; layer profiles are always stored as strings\n",
    "            profile['value'] = profile['value'].astype(float)\n",
    "\n",
    "            # plot the temperature profile\n",
    "            ax.plot(profile['value'], \n",
    "                    profile['depth'], \n",
    "                    marker='.',\n",
    "                    color = cmap(k/len(dates)),\n",
    "                    label=date) \n",
    "            # ax.legend()\n",
    "            \n",
    "            k+=1 \n",
    "            \n",
    "# 5. style the axes\n",
    "for i, site in enumerate(sites):\n",
    "    ax = axes.flatten()[i]\n",
    "    ax.set_xlim(-12, 0)\n",
    "    ax.set_ylim(-10, 110)\n",
    "    ax.set_title(sites[i])\n",
    "    ax.set_xlabel('Temperature [C]')\n",
    "    ax.set_ylabel('Depth [cm]')\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "# close your database session\n",
    "session.close()     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "655cbfa8-ff91-4913-9612-e74c23b1fa4e",
   "metadata": {},
   "source": [
    "## Explore the Spatial Extent of Field Campaign Data\n",
    "### Example 3. Geographically, where do we have measurements? \n",
    "This is my favorite part right here! We are using the ipyleaflet mapping package and our database queries to explore the database.\n",
    "\n",
    "<img src='https://media.giphy.com/media/BPFEy7l8Z9eCphEnNc/giphy.gif' alt='fireworks' style='width:250px' />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8653696-e86b-4d49-b390-d310de2966d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set a map extent\n",
    "bbox = [-125, 49, -102, 31]\n",
    "\n",
    "# set a bounding box\n",
    "west, north, east, south = bbox\n",
    "\n",
    "# add a little bbox buffer\n",
    "bbox_ctr = [0.5*(north+south), 0.5*(west+east)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6035d1-daa0-43bb-82fa-6a1a285e79a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a map, with a somewhat basic backdrop\n",
    "m = Map(basemap=basemaps.CartoDB.Positron, center=bbox_ctr, zoom=4)\n",
    "\n",
    "# add a rectangle to highlight the area of interest\n",
    "rectangle = Rectangle(bounds=((south, west), (north, east))) #SW and NE corners of the rectangle (lat, lon)\n",
    "\n",
    "# add the layer to the map object\n",
    "m.add_layer(rectangle)\n",
    "\n",
    "# view the map\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ddec16-5d3d-483a-83a2-57c5eadc5dcc",
   "metadata": {},
   "source": [
    "More information on available [basemaps](https://ipyleaflet.readthedocs.io/en/latest/map_and_basemaps/basemaps.html) using ipyleaflet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9131fa15-aa94-4226-a20b-6d64a44699b1",
   "metadata": {},
   "source": [
    "### Query the database to add spatial data to our map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba402b2-a46a-4d83-b9c3-0ef9f179fa20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the database\n",
    "db_name = 'snow:hackweek@db.snowexdata.org/snowex'\n",
    "engine, session = get_db(db_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a487a36-1afa-4f46-bc4f-7e4af4304dc5",
   "metadata": {},
   "source": [
    "### Let's find out where we have liquid water content (LWC) data \n",
    "\n",
    "**Pointer -->**  LWC data is in the LayerData table, because data at a single location were measured as a profile on the pit wall face (i.e has a vertical dimension) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d99ac56-7368-41d2-80fb-83d1696bd3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# query the LayerData for all LWC values, this combines a query, filter, and distinct\n",
    "qry = session.query(LayerData.longitude, LayerData.latitude).filter(LayerData.type == 'lwc_vol').distinct() # \n",
    "\n",
    "# convert query to pandas df (LayerData doesn't have the 'geom' column, so can't do geopandas conversion yet\n",
    "df = query_to_pandas(qry, engine)\n",
    "\n",
    "# create the geopandas geometry column from the lat/lon in the pandas df\n",
    "df = gpd.GeoDataFrame(df, geometry=gpd.points_from_xy(df.longitude, df.latitude))\n",
    "\n",
    "print(df.head())\n",
    "\n",
    "# how many did we retrieve?\n",
    "print(f'{len(df.index)} records returned!')\n",
    "\n",
    "# close session to avoid hanging transactions \n",
    "session.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc14ae0-8ce5-4606-8007-4f7b0fefafd5",
   "metadata": {},
   "source": [
    "### Let's add these points to our map!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0f30a0-4814-4973-a49c-80b33ec52d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# same basemap as above\n",
    "m = Map(basemap=basemaps.CartoDB.Positron, center=bbox_ctr, zoom=4)\n",
    "\n",
    "# create a geo_data object\n",
    "geo_data = GeoData(geo_dataframe = df,\n",
    "    style={'color': 'black', 'radius':8, 'fillColor': '#3366cc', 'opacity':0.5, 'weight':1.9, 'dashArray':'2', 'fillOpacity':0.6},\n",
    "    hover_style={'fillColor': 'red' , 'fillOpacity': 0.2},\n",
    "    point_style={'radius': 5, 'color': 'red', 'fillOpacity': 0.8, 'fillColor': 'yellow', 'weight': 3},\n",
    "    name = 'lwc obs.')\n",
    "\n",
    "m.add_layer(geo_data) \n",
    "m.add_control(LayersControl())\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba5fabcc-60b3-4c1a-b09e-2b32a5af667f",
   "metadata": {},
   "source": [
    "## Recap\n",
    "* The database has a lot of power to compare coincident data sets and perform analysis once you gain a few navigational skills \n",
    "* Knowing the different types of data, where they are contained, and practicing queries will help with project work (and don't worry, this was only a preview!)\n",
    "* ipyleaflet is a fun mapping tool!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b39a3a-9eb4-44f3-93a2-0a71b208fbbb",
   "metadata": {},
   "source": [
    "## References \n",
    "several, but best to look at the database tutorial for a one-stop shop!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7eadd55-35c4-4d8b-a2b3-24cbb33f35b5",
   "metadata": {},
   "source": [
    "## Quiz Time! I mean group activity!\n",
    "1. Navigate to this [Google Slides](https://docs.google.com/presentation/d/1tiEiYob_xdRlBXhYXTu-gqeYgOP3rhxjyTGcxXTC8_g/edit#slide=id.p10) page to complete the Data Table activity\n",
    "2. As a large group, move the items into the appropriate database table panel"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
